{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "2023/10/25 23:47:20 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "2023/10/25 23:47:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\mlflow\\pytorch\\_lightning_autolog.py:351: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.0.5 and 2.0.8 and may not succeed with packages outside this range.\"\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 208   \n",
      "1 | decoder | Decoder | 191   \n",
      "------------------------------------\n",
      "399       Trainable params\n",
      "0         Non-trainable params\n",
      "399       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 12/12 [00:00<00:00, 19.57it/s, v_num=64]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 12/12 [00:00<00:00, 19.21it/s, v_num=64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/25 23:48:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at v:\\Code\\cnc-monitoring-system\\notebooks\\lightning_logs\\version_64\\checkpoints\\epoch=39-step=480.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at v:\\Code\\cnc-monitoring-system\\notebooks\\lightning_logs\\version_64\\checkpoints\\epoch=39-step=480.ckpt\n",
      "v:\\Code\\cnc-monitoring-system\\.conda\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 90/90 [00:01<00:00, 59.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02576933614909649    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02576933614909649   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.02576933614909649}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import mlflow\n",
    "import h5py\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "mlflow.set_experiment(\"cnc\")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "class VibrationDataset(data.Dataset):\n",
    "    def __init__(self, root_dir=\"../data\", machine_names=[\"M01\", \"M02\", \"M03\"], process_name=\"OP07\", label=\"good\", seq_length=2000):\n",
    "        self.root_dir = root_dir\n",
    "        self.machine_names = machine_names\n",
    "        self.process_name = process_name\n",
    "        self.label = label\n",
    "        self.seq_length = seq_length\n",
    "        self.data_sequences = []  # List to store sequences\n",
    "\n",
    "        min_value, max_value = -2500.0, 2500.0\n",
    "\n",
    "        # Read data for each machine\n",
    "        for machine_name in self.machine_names:\n",
    "            data_dir = os.path.join(root_dir, machine_name, process_name, label)\n",
    "            file_list = [file for file in os.listdir(data_dir) if file.endswith(\".h5\")]\n",
    "            \n",
    "            # Read and store sequences for each file\n",
    "            for file_name in file_list:\n",
    "                file_path = os.path.join(data_dir, file_name)\n",
    "                \n",
    "                with h5py.File(file_path, \"r\") as hf:\n",
    "                    vibration_data = torch.tensor(hf[\"vibration_data\"][:], dtype=torch.float32)\n",
    "\n",
    "                # Normalize the vibration data to be between -1 and 1\n",
    "                vibration_data = 2 * ((vibration_data - min_value) / (max_value - min_value)) - 1\n",
    "                    \n",
    "                # Splitting the data into sequences\n",
    "                num_full_sequences = len(vibration_data) // self.seq_length\n",
    "                full_sequence_data = vibration_data[:num_full_sequences * self.seq_length]\n",
    "                sequences = full_sequence_data.view(num_full_sequences, self.seq_length, 3)\n",
    "\n",
    "                self.data_sequences.extend(sequences)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data_sequences[idx]\n",
    "        return sequence, sequence  # input and target are the same for autoencoders\n",
    "\n",
    "\n",
    "# Define the LSTM-based Encoder and Decoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, latent_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        _, (h_n, _) = self.lstm2(x)\n",
    "        return h_n\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, seq_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.lstm1 = nn.LSTM(latent_dim, latent_dim)\n",
    "        self.lstm2 = nn.LSTM(latent_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_length, 1, 1)\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        x, (_, _) = self.lstm2(x)\n",
    "        x = self.linear(x)\n",
    "        x = torch.movedim(x, 1, 0)\n",
    "        return x\n",
    "\n",
    "# Define the LSTM-based Autoencoder LightningModule\n",
    "class LSTMAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, seq_length):\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, seq_length)\n",
    "\n",
    "        params = {\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"latent_dim\": latent_dim,\n",
    "            \"seq_length\": seq_length,\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "# Initialize the LSTM-based autoencoder\n",
    "input_dim = 3 # X, Y, Z vibration data\n",
    "hidden_dim = 4  # Arbitrary size for the hidden dimension\n",
    "latent_dim = 2  # Arbitrary size for the latent dimension\n",
    "seq_length = 4000\n",
    "\n",
    "# init the autoencoder\n",
    "autoencoder = LSTMAutoEncoder(input_dim, hidden_dim, latent_dim, seq_length)\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = VibrationDataset(seq_length=seq_length)\n",
    "\n",
    "# Compute the lengths for train/validation split\n",
    "train_len = int(0.8 * len(full_dataset))\n",
    "val_len = len(full_dataset) - train_len\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = data.dataset.random_split(full_dataset, [train_len, val_len])\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "test_dataset = VibrationDataset(label=\"bad\", seq_length=seq_length)\n",
    "test_dataloaders = data.DataLoader(test_dataset)\n",
    "\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=40, log_every_n_steps=10)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "trainer.test(dataloaders=test_dataloaders)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
