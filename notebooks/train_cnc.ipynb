{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import mlflow\n",
    "import h5py\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "mlflow.set_experiment(\"cnc\")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "class VibrationDataset(data.Dataset):\n",
    "    def __init__(self, root_dir=\"../data\", machine_names=[\"M01\", \"M02\", \"M03\"], process_name=\"OP07\", label=\"good\", seq_length=2000):\n",
    "        self.root_dir = root_dir\n",
    "        self.machine_names = machine_names\n",
    "        self.process_name = process_name\n",
    "        self.label = label\n",
    "        self.seq_length = seq_length\n",
    "        self.data_sequences = []  # List to store sequences\n",
    "\n",
    "        min_value, max_value = -2500.0, 2500.0\n",
    "\n",
    "        # Read data for each machine\n",
    "        for machine_name in self.machine_names:\n",
    "            data_dir = os.path.join(root_dir, machine_name, process_name, label)\n",
    "            file_list = [file for file in os.listdir(data_dir) if file.endswith(\".h5\")]\n",
    "            \n",
    "            # Read and store sequences for each file\n",
    "            for file_name in file_list:\n",
    "                file_path = os.path.join(data_dir, file_name)\n",
    "                \n",
    "                with h5py.File(file_path, \"r\") as hf:\n",
    "                    vibration_data = torch.tensor(hf[\"vibration_data\"][:], dtype=torch.float32)\n",
    "\n",
    "                # Normalize the vibration data to be between -1 and 1\n",
    "                vibration_data = 2 * ((vibration_data - min_value) / (max_value - min_value)) - 1\n",
    "                    \n",
    "                # Splitting the data into sequences\n",
    "                num_full_sequences = len(vibration_data) // self.seq_length\n",
    "                full_sequence_data = vibration_data[:num_full_sequences * self.seq_length]\n",
    "                sequences = full_sequence_data.view(num_full_sequences, self.seq_length, 3)\n",
    "\n",
    "                self.data_sequences.extend(sequences)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data_sequences[idx]\n",
    "        return sequence, sequence  # input and target are the same for autoencoders\n",
    "\n",
    "\n",
    "# Define the LSTM-based Encoder and Decoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, latent_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        _, (h_n, _) = self.lstm2(x)\n",
    "        return h_n\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, seq_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.lstm1 = nn.LSTM(latent_dim, latent_dim)\n",
    "        self.lstm2 = nn.LSTM(latent_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_length, 1, 1)\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        x, (_, _) = self.lstm2(x)\n",
    "        x = self.linear(x)\n",
    "        x = torch.movedim(x, 1, 0)\n",
    "        return x\n",
    "\n",
    "# Define the LSTM-based Autoencoder LightningModule\n",
    "class LSTMAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, seq_length):\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, seq_length)\n",
    "\n",
    "        params = {\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"latent_dim\": latent_dim,\n",
    "            \"seq_length\": seq_length,\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=4e-4)\n",
    "        return optimizer\n",
    "\n",
    "# Initialize the LSTM-based autoencoder\n",
    "input_dim = 3 # X, Y, Z vibration data\n",
    "hidden_dim = 4  # Arbitrary size for the hidden dimension\n",
    "latent_dim = 2  # Arbitrary size for the latent dimension\n",
    "seq_length = 4000\n",
    "\n",
    "# init the autoencoder\n",
    "autoencoder = LSTMAutoEncoder(input_dim, hidden_dim, latent_dim, seq_length)\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = VibrationDataset(seq_length=seq_length)\n",
    "\n",
    "# Compute the lengths for train/validation split\n",
    "train_len = int(0.8 * len(full_dataset))\n",
    "val_len = len(full_dataset) - train_len\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = data.dataset.random_split(full_dataset, [train_len, val_len])\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "test_dataset = VibrationDataset(label=\"bad\", seq_length=seq_length)\n",
    "test_dataloaders = data.DataLoader(test_dataset)\n",
    "\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=100, log_every_n_steps=10)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "trainer.test(dataloaders=test_dataloaders)\n",
    "\n",
    "# Get a sample input from your training data\n",
    "sample_input, _ = next(iter(train_dataloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_prediction = autoencoder(sample_input.cpu())  # Ensure the model processes CPU data\n",
    "    sample_input_np = sample_input.cpu().numpy()  # Convert the CPU tensor to numpy\n",
    "    sample_prediction_np = sample_prediction.cpu().numpy()  # Convert the CPU tensor to numpy\n",
    "\n",
    "# Infer the signature\n",
    "signature = mlflow.models.infer_signature(sample_input_np, sample_prediction_np)\n",
    "\n",
    "# 3. Log the model with signature\n",
    "run_id = mlflow.active_run().info.run_id\n",
    "mlflow.pytorch.log_model(autoencoder, \"model\", signature=signature)\n",
    "\n",
    "sample_input_single_batch = sample_input[:1]\n",
    "onnx_dir = \"onnx_models/\"\n",
    "os.makedirs(onnx_dir, exist_ok=True)\n",
    "onnx_file_path = os.path.join(onnx_dir, f\"{run_id}.onnx\")\n",
    "autoencoder.to_onnx(onnx_file_path, sample_input_single_batch, export_params=True)\n",
    "\n",
    "print(f\"Exported ONNX model saved at: {onnx_file_path}\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"***** DONE *****\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
